{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import subprocess\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACS_5yr_Seq_Table_Number_Lookup = pandas.read_excel(\"../../reference_files/ACS_5yr_Seq_Table_Number_Lookup.xls\")\n",
    "ACS_5yr_Seq_Table_Number_Lookup[\"Sequence Number\"] = ACS_5yr_Seq_Table_Number_Lookup[\"Sequence Number\"].apply(lambda x: f\"{x}\".zfill(4))\n",
    "ACS_5yr_Seq_Table_Number_Lookup[\"Line Number\"] = ACS_5yr_Seq_Table_Number_Lookup[\"Line Number\"].apply(lambda x: x if pandas.isna(x) else f\"{int(x)}\".replace(\".0\",\"\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFile(state_abr, url,fnm,seq_num,var_name,var_postion,line_num):   \n",
    "    all_gfiles_name = \"../../reference_files/5_year_Mini_Geo.xlsx\"    \n",
    "    completed = subprocess.run(['mkdir',f\"{WORKING_DIR}/{state_abr}\"],stdout=subprocess.PIPE)\n",
    "    print('returncode:', completed.returncode)\n",
    "    print('Have {} bytes in stdout:\\n{}'.format(len(completed.stdout),completed.stdout.decode('utf-8')))\n",
    "    print(url)\n",
    "    completed = subprocess.run(['wget', '-O' ,f\"{WORKING_DIR}/{state_abr}/{fnm}\", \"--connect-timeout=5\", f\"{url}\"],stdout=subprocess.PIPE)\n",
    "    print('returncode:', completed.returncode)\n",
    "    print('Have {} bytes in stdout:\\n{}'.format(len(completed.stdout),completed.stdout.decode('utf-8')))\n",
    "    print(f\"{WORKING_DIR}/{state_abr}/{fnm}\")\n",
    "    zf = zipfile.ZipFile(f\"{WORKING_DIR}/{state_abr}/{fnm}\")\n",
    "    fsize = sum([zinfo.file_size for zinfo in  zf.filelist])\n",
    "    zip_kb = float(fsize)/1000 #kB\n",
    "    print(\"file_size\",zip_kb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rslst = []\n",
    "WORKING_DIR = \"../../reference_files/\"\n",
    "var_names=[\n",
    "            'B17021_001E',\n",
    "            'B17021_002E',\n",
    "            'B03002_001E',\n",
    "            'B03002_003E',\n",
    "            'B03002_004E',\n",
    "            'B03002_006E',\n",
    "            'B03002_012E',\n",
    "            'B25008_001E',\n",
    "            'B25008_003E',\n",
    "            'B99051_001E',\n",
    "            'B99051_005E',\n",
    "            'B99051_006E',\n",
    "            'B99051_007E',\n",
    "            'B15003_001E',\n",
    "            'B15003_022E',\n",
    "            'B15003_023E',\n",
    "            'B15003_024E',\n",
    "            'B15003_025E',\n",
    "    \n",
    "            'B25010_001E', # average housing unit size (for occupied hunits)\n",
    "            'B25010_002E',\n",
    "            'B25010_003E',\n",
    "    \n",
    "            'B25036_001E', # by year structure was built (for occupied hunits)\n",
    "            'B25036_012E',\n",
    "            'B25036_011E',\n",
    "            'B25036_010E',\n",
    "            'B25036_009E',\n",
    "            'B25036_008E',\n",
    "            'B25036_007E',\n",
    "            'B25036_006E',\n",
    "    \n",
    "            'B25036_023E',\n",
    "            'B25036_022E',\n",
    "            'B25036_021E',\n",
    "            'B25036_020E',\n",
    "            'B25036_019E',\n",
    "            'B25036_018E',\n",
    "            'B25036_017E',\n",
    "    \n",
    "            'B23025_004E', # emplynt\n",
    "            'B23025_005E',\n",
    "            'B23025_003E',\n",
    "    \n",
    "    \n",
    "            'B25001_001E', # housing units (total)\n",
    "            'B25004_001E' # vacant units\n",
    "    \n",
    "            ]\n",
    "\n",
    "state_code_abbr = pandas.read_csv(f\"{WORKING_DIR}/state.txt\", delimiter='|', dtype={\"STATE_NAME\":str,\"STUSAB\":str,\"STATE\":str},index_col=False)\n",
    "state_code_abbr[\"STATE\"] = state_code_abbr[\"STATE\"].apply(lambda x: x.zfill(2))\n",
    "ratiodf = pandas.read_csv(f\"{WORKING_DIR}/merged_fin.csv\",dtype={\"blg\":str})\n",
    "ratiodf[\"blg\"] = ratiodf[\"blg\"].apply(lambda x: f\"{x}\".zfill(12))\n",
    "ratiodf['blg'] = ratiodf['blg'].apply(lambda x: f\"{x}\".zfill(12))\n",
    "# get a list of states and get all the data for them\n",
    "ratiodf[\"state_code\"] = ratiodf['blg'].apply(lambda x: f\"{x}\"[:2])\n",
    "ratiodf = ratiodf.loc[ratiodf[\"state_code\"]!=\"00\",]\n",
    "for state_code in ratiodf.groupby(\"state_code\", as_index=False).min()[\"state_code\"].unique(): #[:4]\n",
    "    STATEABBR = state_code_abbr.loc[state_code_abbr[\"STATE\"]==state_code,][\"STUSAB\"].values[0]\n",
    "    STATENAME = state_code_abbr.loc[state_code_abbr[\"STATE\"]==state_code,][\"STATE_NAME\"].values[0]\n",
    "    if f\"{STATEABBR}\" in files_inventrory:\n",
    "        pass\n",
    "    else:\n",
    "        files_inventrory.update({f\"{STATEABBR}\":{}})\n",
    "    stateabbr = STATEABBR\n",
    "    state_ratiodf = ratiodf.loc[ratiodf[\"state_code\"]==state_code,[\"blg\",\"CITYNAME\",\"state_code\",\"GEO_blg\"]]\n",
    "    for VARNAME in var_names:\n",
    "        varname = VARNAME\n",
    "        url_seq_file_for_state_base = f\"https://www2.census.gov/programs-surveys/acs/summary_file/2015/data/5_year_seq_by_state/{STATENAME.replace(' ','')}/Tracts_Block_Groups_Only/\"\n",
    "        TABLENAME = varname.split('_')[0]\n",
    "        STATENAME_gfile_name = f\"g20155{stateabbr.lower()}.zip\"\n",
    "        LINENUM = int(varname.split('_')[1].replace(\"E\",\"\"))\n",
    "        print(f\"LINENUM: {LINENUM}\")\n",
    "        _tumber_for_t  = ACS_5yr_Seq_Table_Number_Lookup.loc[ACS_5yr_Seq_Table_Number_Lookup[\"Table ID\"]==TABLENAME,]# seq_tumber_for_t\n",
    "        seq_tumber_for_t = _tumber_for_t [\"Sequence Number\"].values[0]\n",
    "        print(f\"seq_tumber_for_t: {seq_tumber_for_t}\")\n",
    "        VARSTARTPOSITION = int(_tumber_for_t.loc[_tumber_for_t[\"Start Position\"].notnull(),][\"Start Position\"].values[0])\n",
    "        print(f\"VARSTARTPOSITION: {VARSTARTPOSITION}\")\n",
    "        seq_url_filename_patt = f'20155{stateabbr.lower()}{seq_tumber_for_t}000.zip'\n",
    "        url_seq_file_for_state = f\"{url_seq_file_for_state_base}{seq_url_filename_patt}\"\n",
    "\n",
    "        if f\"{seq_tumber_for_t}\" in files_inventrory[f\"{STATEABBR}\"]:\n",
    "            print(\"downloaded\")\n",
    "        else: \n",
    "    #         try:\n",
    "            getFile(STATEABBR, url_seq_file_for_state,seq_url_filename_patt,seq_tumber_for_t, varname,VARSTARTPOSITION, LINENUM)\n",
    "            files_inventrory[f\"{STATEABBR}\"][f\"{seq_tumber_for_t}\"] = \"downloaded\"\n",
    "            print(\"downloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_gfiles_name = \"../../reference_files/5_year_Mini_Geo.xlsx\"\n",
    "for state_code in ratiodf.groupby(\"state_code\", as_index=False).min()[\"state_code\"].unique(): #[:4]\n",
    "    STATEABBR = state_code_abbr.loc[state_code_abbr[\"STATE\"]==state_code,][\"STUSAB\"].values[0]\n",
    "    STATENAME = state_code_abbr.loc[state_code_abbr[\"STATE\"]==state_code,][\"STATE_NAME\"].values[0]\n",
    "    __omall_gfiles = pandas.read_excel(f\"{WORKING_DIR}/{all_gfiles_name}\",dtype={\"GEOID\":str,\"LOGRECNO\":str},sheet_name=STATEABBR,index_col=False)\n",
    "    __omall_gfiles[\"summ_level\"] = __omall_gfiles[\"GEOID\"].apply(lambda x: x[:7])\n",
    "    fromall_gfiles = __omall_gfiles.loc[__omall_gfiles[\"summ_level\"] == \"15000US\",]\n",
    "    fromall_gfiles.to_csv(f\"{WORKING_DIR}/{STATEABBR}/geography_summ_level_bg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_names=[\n",
    "            'B17021_001E',\n",
    "            'B17021_002E',\n",
    "            'B03002_001E',\n",
    "            'B03002_003E',\n",
    "            'B03002_004E',\n",
    "            'B03002_006E',\n",
    "            'B03002_012E',\n",
    "            'B25008_001E',\n",
    "            'B25008_003E',\n",
    "            'B99051_001E',\n",
    "            'B99051_005E',\n",
    "            'B99051_006E',\n",
    "            'B99051_007E',\n",
    "            'B15003_001E',\n",
    "            'B15003_022E',\n",
    "            'B15003_023E',\n",
    "            'B15003_024E',\n",
    "            'B15003_025E',\n",
    "    \n",
    "            'B25010_001E', # average housing unit size (for occupied hunits)\n",
    "            'B25010_002E',\n",
    "            'B25010_003E',\n",
    "    \n",
    "            'B25036_001E', # by year structure was built (for occupied hunits)\n",
    "            'B25036_012E',\n",
    "            'B25036_011E',\n",
    "            'B25036_010E',\n",
    "            'B25036_009E',\n",
    "            'B25036_008E',\n",
    "            'B25036_007E',\n",
    "            'B25036_006E',\n",
    "    \n",
    "            'B25036_023E',\n",
    "            'B25036_022E',\n",
    "            'B25036_021E',\n",
    "            'B25036_020E',\n",
    "            'B25036_019E',\n",
    "            'B25036_018E',\n",
    "            'B25036_017E',\n",
    "    \n",
    "    \n",
    "    \n",
    "            'B23025_004E', # emplynt\n",
    "            'B23025_005E',\n",
    "            'B23025_003E',\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "            'B25001_001E', # housing units (total)\n",
    "            'B25004_001E' # vacant units\n",
    "            ]\n",
    "\n",
    "\n",
    "for state_code in ratiodf.groupby(\"state_code\", as_index=False).min()[\"state_code\"].unique(): #[:4]\n",
    "    STATEABBR = state_code_abbr.loc[state_code_abbr[\"STATE\"]==state_code,][\"STUSAB\"].values[0]\n",
    "    STATENAME = state_code_abbr.loc[state_code_abbr[\"STATE\"]==state_code,][\"STATE_NAME\"].values[0]\n",
    "    for VARNAME in var_names:\n",
    "        TABLENAME = VARNAME.split('_')[0]\n",
    "        STATENAME_gfile_name = f\"g20155{STATEABBR.lower()}.zip\"\n",
    "        LINENUM = int(VARNAME.split('_')[1].replace(\"E\",\"\"))\n",
    "        _tumber_for_t  = ACS_5yr_Seq_Table_Number_Lookup.loc[ACS_5yr_Seq_Table_Number_Lookup[\"Table ID\"]==TABLENAME,]# seq_tumber_for_t\n",
    "        seq_tumber_for_t = _tumber_for_t [\"Sequence Number\"].values.min()\n",
    "        if (_tumber_for_t [\"Sequence Number\"].values.min() != _tumber_for_t [\"Sequence Number\"].values.max()):\n",
    "            print(\"MULTIPLE SEQQ WARNING\")\n",
    "        _tumber_for_t_s = _tumber_for_t.loc[_tumber_for_t[\"Sequence Number\"] == seq_tumber_for_t,]\n",
    "        VARSTARTPOSITION = int(_tumber_for_t_s.loc[_tumber_for_t_s[\"Start Position\"].notnull(),][\"Start Position\"].values[0])\n",
    "        seq_url_filename_patt = f'20155{STATEABBR.lower()}{seq_tumber_for_t}000.zip'\n",
    "        zf = zipfile.ZipFile(f\"{WORKING_DIR}/{STATEABBR}/{seq_url_filename_patt}\")\n",
    "        fsize = sum([zinfo.file_size for zinfo in  zf.filelist])\n",
    "        zip_kb = float(fsize)/1000 #kB\n",
    "        print(\"file_size\",zip_kb)\n",
    "        logrecno = list()\n",
    "        varvals = list()\n",
    "        with zf.open(f\"e{seq_url_filename_patt.replace('.zip','.txt')}\") as fle:\n",
    "            for lne in fle:\n",
    "                logrecno.append(lne.decode().split(\",\")[5])\n",
    "                varvals.append(lne.decode().split(\",\")[VARSTARTPOSITION+LINENUM-2])\n",
    "        statevarseqfile = pandas.DataFrame({\n",
    "            \"LOGRECNO\":logrecno,\n",
    "            f\"{VARNAME}\": varvals\n",
    "        })\n",
    "        statevarseqfile.to_csv(f\"{WORKING_DIR}/{STATEABBR}/{VARNAME}_seqfile.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state_code in ratiodf.groupby(\"state_code\", as_index=False).min()[\"state_code\"].unique(): #[:4]\n",
    "    STATEABBR = state_code_abbr.loc[state_code_abbr[\"STATE\"]==state_code,][\"STUSAB\"].values[0]\n",
    "    STATENAME = state_code_abbr.loc[state_code_abbr[\"STATE\"]==state_code,][\"STATE_NAME\"].values[0]\n",
    "    for VARNAME in var_names:\n",
    "        TABLENAME = VARNAME.split('_')[0]\n",
    "        statevarle = pandas.read_csv(f\"{WORKING_DIR}/{STATEABBR}/{VARNAME}_seqfile.csv\")\n",
    "        statevarle.set_index(\"LOGRECNO\", inplace=True)\n",
    "        stategeodfle = pandas.read_csv(f\"{WORKING_DIR}/{STATEABBR}/geography_summ_level_bg.csv\")\n",
    "        stategeodfle.set_index(\"LOGRECNO\", inplace=True)\n",
    "        statevarjoin = stategeodfle.join(statevarle, lsuffix=\"_geo\",rsuffix=\"_seq\")\n",
    "        statevarjoin.to_csv(f\"{WORKING_DIR}/{STATEABBR}/{VARNAME}_GEO.csv\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state_code in ratiodf.groupby(\"state_code\", as_index=False).min()[\"state_code\"].unique(): #[:4]\n",
    "    STATEABBR = state_code_abbr.loc[state_code_abbr[\"STATE\"]==state_code,][\"STUSAB\"].values[0]\n",
    "    STATENAME = state_code_abbr.loc[state_code_abbr[\"STATE\"]==state_code,][\"STATE_NAME\"].values[0]\n",
    "    states_tables_list = []\n",
    "    for VARNAME in var_names:\n",
    "        TABLENAME = VARNAME.split('_')[0]\n",
    "        statevarjointable = pandas.read_csv(f\"{WORKING_DIR}/{STATEABBR}/{VARNAME}_GEO.csv\", index_col=\"GEOID\")\n",
    "        states_tables_list.append(statevarjointable)\n",
    "    _mdf = states_tables_list.pop(0)\n",
    "    for __df in states_tables_list:\n",
    "        \n",
    "        _mdf =_mdf.append(__df)\n",
    "    _mdf = _mdf.groupby(_mdf.index).sum()\n",
    "    _mdf.to_csv(f\"{WORKING_DIR}/{STATEABBR}/geo_2015_5yrs.csv\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
